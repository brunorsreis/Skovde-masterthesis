#!/usr/bin/env python
# coding: utf-8

# In[ ]:


#Appendix A - Source Code of the AI-Enhanced Forensic Tool with Cohere LLM
import os, re, json, logging, warnings, tempfile
import pdfplumber
import pandas as pd
import matplotlib.pyplot as plt
from sentence_transformers import SentenceTransformer
import gradio as gr
from docx import Document
import oracledb
import cohere

# --- Setup ---
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
warnings.filterwarnings("ignore")
embedder = SentenceTransformer('all-MiniLM-L6-v2')

# --- DB Setup ---
conn = oracledb.connect(user="******", password="*****", dsn="localhost:1522/FREEPDB1")
#Replace **** with your user and password as well the right dsn values
cur = conn.cursor()
cur.execute("BEGIN EXECUTE IMMEDIATE 'DROP TABLE forensic_vectors'; EXCEPTION WHEN OTHERS THEN NULL; END;")
cur.execute("""
CREATE TABLE forensic_vectors (
    id NUMBER GENERATED BY DEFAULT ON NULL AS IDENTITY,
    filename VARCHAR2(255),
    content CLOB,
    embedding CLOB
)
""")

# --- Risk Info Dictionary ---
risk_info = {
    "email": {
        "description": "Emails can be used for phishing or impersonation.",
        "risks": ["Phishing attacks", "Credential stuffing", "Identity theft"],
        "mitigation": ["Mask or obfuscate emails", "Avoid plain-text storage", "Limit email sharing"]
    },
    "phone": {
        "description": "Phones can be used in smishing or SIM swapping.",
        "risks": ["Smishing attacks", "SIM hijacking", "Privacy violations"],
        "mitigation": ["Redact phone numbers", "Avoid storing personal numbers", "Use MFA-aware protection"]
    },
    "credit_card": {
        "description": "Card numbers can lead to fraud or compliance issues.",
        "risks": ["Unauthorized transactions", "PCI violations"],
        "mitigation": ["Use tokenization", "Never store raw card numbers", "Encrypt at rest"]
    },
    "password": {
        "description": "Passwords risk account takeover if exposed.",
        "risks": ["Account hijacking", "Credential reuse attacks"],
        "mitigation": ["Avoid storing passwords", "Use password managers", "Enforce rotation"]
    },
    "ip_address": {
        "description": "IPs reveal network surfaces for potential attack.",
        "risks": ["DDoS", "Reconnaissance", "Traffic profiling"],
        "mitigation": ["Mask internal IPs", "Use firewalls/NAT", "Restrict logs access"]
    }
}

# --- File Reader ---
def read_file_content(file_path):
    ext = os.path.splitext(file_path)[1].lower()
    try:
        if ext == ".pdf":
            with pdfplumber.open(file_path) as pdf:
                return "\n".join(page.extract_text() or "" for page in pdf.pages)
        elif ext in [".txt", ".log", ".md"]:
            return open(file_path, 'r', encoding='utf-8', errors='ignore').read()
        elif ext == ".csv":
            return pd.read_csv(file_path).to_string(index=False)
        elif ext == ".json":
            return json.dumps(json.load(open(file_path, 'r', encoding='utf-8')), indent=2)
        elif ext == ".docx":
            return "\n".join(p.text for p in Document(file_path).paragraphs if p.text.strip())
        elif ext == ".doc":
            return "[Binary .doc file - content not extracted. Please use .docx or .pdf]"
        else:
            return open(file_path, 'rb').read().decode('utf-8', errors='ignore')
    except Exception as e:
        return f"‚ùå Error reading {file_path}: {e}"

# --- Context-Based Filtering for Phone Numbers ---
def context_based_filter(text, matches, label):
    if label == "phone":
        filtered = []
        for m in matches:
            context_window = 100
            idx = text.find(m)
            if idx != -1:
                context = text[max(0, idx-context_window):idx+context_window]
                if re.search(r"(phone|tel|contact)", context, re.IGNORECASE):
                    filtered.append(m)
        return filtered
    return matches

# --- Sensitive Info Detection ---
def detect_sensitive_info(text):
    patterns = {
        "email": r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,6}\b',
        "phone": r'\b(?:\+?\d{1,3}[ \.-]?)?(?:\(?\d{2,4}\)?[ \.-]?)?\d{3}[ \.-]?\d{3,4}\b',
        "credit_card": r'\b(?:\d[ -]*?){13,16}\b',
        "password": r'(?i)\bpassword\s*[:=]\s*\S+',
        "ip_address": r'\b(?:\d{1,3}\.){3}\d{1,3}\b'
    }

    findings = []
    for label, pattern in patterns.items():
        matches = re.findall(pattern, text)
        if matches:
            if label == "phone":
                matches = [m for m in matches if not re.fullmatch(r'\d+(\.\d+)?', m.strip())]
                matches = context_based_filter(text, matches, label)
            if matches:
                findings.append((label, matches))
    return findings

# --- Cohere Summarizer ---
COHERE_API_KEY = os.getenv("COHERE_API_KEY", "********")
#Replace **** with your COHERE_API_KEY from https://dashboard.cohere.com/
co = cohere.Client(COHERE_API_KEY)

def cohere_llm(text):
    prompt_text = (
        "You are a cybersecurity forensic AI. Analyze the following:\n"
        "1. Identify sensitive data (emails, IPs, passwords, credit cards).\n"
        "2. Assess exposure severity.\n"
        "3. Suggest mitigations.\n\n"
        f"{text[:4000]}"
    )
    try:
        response = co.generate(
            model="command-r-plus",
            prompt=prompt_text,
            max_tokens=300,
            temperature=0.5,
            p=0.9
        )
        return response.generations[0].text.strip()
    except Exception as e:
        return f"‚ùå Cohere API Error: {e}"

# --- Bar Chart: Combined View ---
def generate_bar_chart(all_findings):
    total_counts = {}
    for findings in all_findings:
        for label, matches in findings:
            total_counts[label] = total_counts.get(label, 0) + len(matches)

    if not total_counts:
        return None

    plt.figure(figsize=(8, 5))
    bars = plt.bar(total_counts.keys(), total_counts.values(), color=plt.cm.Set3.colors)
    plt.title("Total Sensitive Data Detected")
    plt.xlabel("Type")
    plt.ylabel("Count")
    plt.grid(axis='y', linestyle='--', alpha=0.6)

    for bar in bars:
        height = bar.get_height()
        plt.annotate(f'{int(height)}', xy=(bar.get_x() + bar.get_width() / 2, height),
                     xytext=(0, 3), textcoords="offset points", ha='center', va='bottom')

    chart_path = tempfile.NamedTemporaryFile(delete=False, suffix=".png").name
    plt.tight_layout()
    plt.savefig(chart_path)
    plt.close()
    return chart_path

# --- Analyzer ---
def analyze_with_chart(files, _):
    results = []
    all_findings = []

    for file in files if isinstance(files, list) else [files]:
        path = file.name
        logger.info(f"üîç Processing: {path}")
        text = read_file_content(path)
        if text.startswith("‚ùå") or text.startswith("[Binary .doc file"):
            results.append(text)
            continue

        sensitive = detect_sensitive_info(text)
        all_findings.append(sensitive)
        emb_json = json.dumps(embedder.encode(text).tolist())

        try:
            cur.execute("""
                INSERT INTO forensic_vectors (filename, content, embedding)
                VALUES (:fn, :ct, :em)
            """, {"fn": os.path.basename(path), "ct": text, "em": emb_json})
            conn.commit()
            db_status = "üü¢ Stored in DB."
        except Exception as e:
            db_status = f"‚ùå DB Error: {e}"

        sensitive_str = ""
        for label, matches in sensitive:
            sensitive_str += f"\n\nüìå {label.upper()} ({len(matches)} found)\n" + "\n".join(f" - {m}" for m in matches)
            info = risk_info.get(label)
            if info:
                sensitive_str += f"\n\nüõ†Ô∏è Risks:\n" + "\n".join(f" - {r}" for r in info['risks'])
                sensitive_str += f"\n\nüîê Mitigations:\n" + "\n".join(f" - {m}" for m in info['mitigation'])

        if not sensitive_str.strip():
            sensitive_str = "No sensitive data found."

        llm_result = cohere_llm(text)
        results.append(f"""
üìÑ File: {os.path.basename(path)}
{db_status}

üîç Sensitive Info:
{sensitive_str}

üß† LLM Summary (Cohere):
{llm_result}
""".strip())

    # Final chart from all findings
    chart = generate_bar_chart(all_findings)

    # Write flag file
    flag_path = os.path.join(tempfile.gettempdir(), "forensic_flag.txt")
    with open(flag_path, "w") as flag_file:
        flag_file.write("‚úÖ Forensic scan complete.\n")
        for file in files:
            flag_file.write(f"- {file.name}\n")

    return "\n\n".join(results), chart, flag_path

# --- Gradio UI ---
gr.Interface(
    fn=analyze_with_chart,
    inputs=[
        gr.File(label="üìÅ Upload Files", file_count="multiple"),
        gr.Textbox(label="(Optional) OCI Compartment OCID (ignored for Cohere)")
    ],
    outputs=[
        gr.Text(label="üìÑ Forensic Report"),
        gr.Image(label="üìä Sensitive Info Chart"),
        gr.File(label="üì• Download Flag File")
    ],
    title="üîê Cyber Forensic Analyzer with Cohere",
    description="Upload files (PDF, DOC, DOCX, TXT, CSV, JSON). Detect sensitive data, visualize results, and download forensic flag."
).launch()

